<!doctype html>
<html lang="en">
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y47DH1GQX9"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-Y47DH1GQX9');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Alexandre Gramfort, ">

        <link rel="alternate"  href="http://alexandre.gramfort.net/feeds/all.atom.xml" type="application/atom+xml" title="Alexandre Gramfort Full Atom Feed"/>

        <title>Alexandre Gramfort // </title>


    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="./theme/css/pure.css">
    <link rel="stylesheet" href="./theme/css/academicons.css">


    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
</head>

<body>
<div class="pure-g-r" id="layout">
<div class="sidebar pure-u">
    <div class="cover-img" style="background: none repeat scroll 0% 0% #014c71">
        <div class="cover-body">
            <header class="header">
            <hgroup>
                    <a href="/">
                        <img class="avatar" src="/images/picture3.jpg">
                    </a>

                <nav id="nav">

                    <h2><a href="/">Alexandre Gramfort</a></h2>

                    <p class="brand-main-sub">
                        <em>Senior Research Scientist,
                        <a href="http://www.meta.com/">Meta</a>
                        </em>
                        <br />
                        <em>(Ex-) Research director, HdR</em>
                        <br />
                        <a href="http://www.inria.fr/">Inria</a>,
                        <span class="no-show-media">
                            <a href="http://team.inria.fr/mind/"
                            title="Inria MIND">MIND Team</a>
                        </span>
                        <br />
                        Univ. Paris Saclay
                    </p>

                    <p class="brand-main-sub no-show-media">
                        I do: <br/>
                        Machine Learning, Signal and Image Processing, Brain functional imaging (MEG, EEG, fMRI), Optimization, Scientific Computing, Software Engineering
                    </p>

                    <p>
                        <ul>
                            <li class="nav"><a href="publications.html" id="publications-link" class="skel-layers-ignoreHref">Publications</a></li>
                            <li class="nav"><a href="index.html#shortbio" id="about-link" class="skel-layers-ignoreHref">Short Bio</a></li>
                            <li class="nav"><a href="index.html#software" id="software-link" class="skel-layers-ignoreHref">Software</a></li>
                            <li class="nav"><a href="index.html#team" id="team-link" class="skel-layers-ignoreHref">Team</a></li>
<!--                             <li class="nav"><a href="index.html#news" id="news-link" class="skel-layers-ignoreHref">News</a></li>
 -->                        </ul>
                    </p>
                </nav>

                <p class="tagline"></p>


                <p class="social">
                <a href="https://github.com/agramfort/">
                    <i class="fa fa-github fa-3x"></i>
                </a>
                <a href="https://twitter.com/agramfort">
                    <i class="fa fa-twitter-square fa-3x"></i>
                </a>
                <a href="https://scholar.google.com/citations?user=fhxshS0AAAAJ">
                    <i class="ai ai-google-scholar-square ai-3x"></i>
                </a>
                <a href="https://www.linkedin.com/in/alexandregramfort">
                    <i class="fa fa-linkedin fa-3x"></i>
                </a>
                <a href="https://slideslive.com/s/alexandre-gramfort-30748">
                    <i class="fa fa-slideshare fa-3x"></i>
                </a>
                <a href="https://www.youtube.com/playlist?list=PLHbs5LeOxdhIpGOmbEYhOXtpo0yFK6cRk">
                    <i class="fa fa-youtube fa-3x"></i>
                </a>
                </p>
            </hgroup>
            </header>
        </div>
    </div>
</div>    <div class="pure-u-1">
        <div class="content">
            <div id="publications" class="posts" >
                <h1 class="content-nicehead">
                    ANR Chaire IA: <br>
                    Bridging Artificial Intelligence and Neuroscience (<a href="https://anr.fr/fr/actualites-de-lanr/details/news/publication-des-resultats-de-lappel-a-projets-chaires-de-recherche-et-denseignement-en-intellige/">BrAIN</a>)
                </h1>
                <p style="text-align: center;">
                    <img src="images/anr_logo.png" alt="ANR Agence Nationale de le Recherche">
                </p>
                <p>
                    <b>Summary:</b>

Artificial intelligence (AI) with recent progress in statistical machine learning (ML) is currently aiming to revolutionise how experimental science is conducted. In physics, chemistry, biology, neuroscience or medicine, data is now the driver of new theoretical insights and new scientific hypotheses. Supervised learning and predictive models are now used to assess if something is “predictable”: Can I predict what people “think” from neural signals? Can I predict from DNA if a patient will suffer from cancer? ML is now used as a replacement for classical statistical hypothesis testing. In healthcare, one talks about precision medicine, virtual patients with the vision that artificial intelligence will allow to have individualised predictions from genomic, physiological or imaging data.
After pioneering breakthroughs in computer vision, speech processing or natural language processing, ML has now to face new challenges in order to impact various scientific disciplines and in particular health related applications. When considering medical applications, statistical and computational problems emerge. i) The first problem is related to the absence or limited amount supervision for algorithms: supervised predictive models need so-called annotations or labels to be trained and tested, and unfortunately too few medical applications can provide enough of these. ii) The second problem is related to what can be phrased as dataset variability, or in more statistical terms, distribution or covariate shifts. What has been called in computer vision the “dataset bias” problem, implies that training on data from a certain hospital is likely to provide less powerful prediction when testing on data from a different hospital. iii) The third problem is related to the difficulty of bringing the state-of-the-art tools to an environment that is not dominated by computer scientists but biologists, neuroscientists, psychologists, medical doctors. BrAIN aims to provide the next generation of ML models and algorithms for efficient statistical learning in the absence of strong labels and large sample sizes. BrAIN will leverage clear use-cases in clinical and cognitive neuroscience (anaesthesia, disorders of consciousness, sleep medicine) to address general ML challenges: 1) study of various self-supervised learning tasks to learn from long and noisy temporal data 2) learning to augment data and increase sample sizes 3) robust learning in the presence of distribution shifts 4) development of tractable algorithms easy to use by non-experts.

                </p>
                <h2 class="content-subhead">Publications related to the BrAIN Project:</h2>
<p class="post-meta">
    <b>Multi-Source and Test-Time Domain Adaptation on Multivariate Signals using Spatio-Temporal Monge Alignment</b><br/>
    Gnassounou T., Collas A., Flamary R., Lounici K., <strong><em>Gramfort A.</em></strong> (2024)
    <br/>
        <a href="https://arxiv.org/abs/2407.14303">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_2">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_2_content">
            <pre>@misc{gnassounou2024multisourcetesttimedomainadaptation,
 archiveprefix = {arXiv},
 author = {Gnassounou, Théo and Collas, Antoine and Flamary, Rémi and Lounici, Karim and Gramfort, Alexandre},
 eprint = {2407.14303},
 primaryclass = {cs.LG},
 title = {Multi-Source and Test-Time Domain Adaptation on Multivariate Signals using Spatio-Temporal Monge Alignment},
 url = {https://arxiv.org/abs/2407.14303},
 year = {2024}
}</pre>
        </div>
</p><p class="post-meta">
    <b>SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation</b><br/>
    Lalou Y., Gnassounou T., Collas A., de Mathelin A., Kachaiev O., Odonnat A., <strong><em>Gramfort A.</em></strong>, Moreau T., Flamary R. (2024)
    <br/>
        <a href="https://arxiv.org/abs/2407.11676">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_3">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_3_content">
            <pre>@misc{lalou2024skadabenchbenchmarkingunsuperviseddomain,
 archiveprefix = {arXiv},
 author = {Lalou, Yanis and Gnassounou, Théo and Collas, Antoine and de Mathelin, Antoine and Kachaiev, Oleksii and Odonnat, Ambroise and Gramfort, Alexandre and Moreau, Thomas and Flamary, Rémi},
 eprint = {2407.11676},
 primaryclass = {cs.LG},
 title = {SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation},
 url = {https://arxiv.org/abs/2407.11676},
 year = {2024}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Geodesic Optimization for Predictive Shift Adaptation on EEG data</b><br/>
    Mellot A., Collas A., Chevallier S., <strong><em>Gramfort A.</em></strong>, Engemann D. (2024)
    <br/>
        <a href="https://arxiv.org/abs/2407.03878">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_4">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_4_content">
            <pre>@misc{mellot2024geodesicoptimizationpredictiveshift,
 archiveprefix = {arXiv},
 author = {Mellot, Apolline and Collas, Antoine and Chevallier, Sylvain and Gramfort, Alexandre and Engemann, Denis A.},
 eprint = {2407.03878},
 primaryclass = {stat.ML},
 title = {Geodesic Optimization for Predictive Shift Adaptation on EEG data},
 url = {https://arxiv.org/abs/2407.03878},
 year = {2024}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Do try this at home: Age prediction from sleep and meditation with large-scale low-cost mobile EEG</b><br/>
    Banville H., Jaoude M., Wood S., Aimone C., Holst S., <strong><em>Gramfort A.</em></strong>, Engemann D. (2024)
        <br/>
        Imaging Neuroscience
            2: (1-15).
    <br/>
        <a href="https://doi.org/10.1162/imag\_a\_00189">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_5">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_5_content">
            <pre>@article{10.1162/imag_a_00189,
 abstract = {{Electroencephalography (EEG) is an established method for quantifying large-scale neuronal dynamics which enables diverse real-world biomedical applications, including brain-computer interfaces, epilepsy monitoring, and sleep staging. Advances in sensor technology have freed EEG from traditional laboratory settings, making low-cost ambulatory or at-home assessments of brain function possible. While ecologically valid brain assessments are becoming more practical, the impact of their reduced spatial resolution and susceptibility to noise remain to be investigated. This study set out to explore the potential of at-home EEG assessments for biomarker discovery using the brain age framework and four-channel consumer EEG data. We analyzed recordings from more than 5200 human subjects (18–81 years) during meditation and sleep, to predict age at the time of recording. With cross-validated R2 scores between 0.3-0.5, prediction performance was within the range of results obtained by recent benchmarks focused on laboratory-grade EEG. While age prediction was successful from both meditation and sleep recordings, the latter led to higher performance. Analysis by sleep stage uncovered that N2-N3 stages contained most of the signal. When combined, EEG features extracted from all sleep stages gave the best performance, suggesting that the entire night of sleep contains valuable age-related information. Furthermore, model comparisons suggested that information was spread out across electrodes and frequencies, supporting the use of multivariate modeling approaches. Thanks to our unique dataset of longitudinal repeat sessions spanning 153 to 529 days from eight subjects, we finally evaluated the variability of EEG-based age predictions, showing that they reflect both trait- and state-like information. Overall, our results demonstrate that state-of-the-art machine-learning approaches based on age prediction can be readily applied to real-world EEG recordings obtained during at-home sleep and meditation practice.}},
 author = {Banville, Hubert and Jaoude, Maurice Abou and Wood, Sean U.N. and Aimone, Chris and Holst, Sebastian C. and Gramfort, Alexandre and Engemann, Denis-Alexander},
 doi = {10.1162/imag_a_00189},
 eprint = {https://direct.mit.edu/imag/article-pdf/doi/10.1162/imag\_a\_00189/2385985/imag\_a\_00189.pdf},
 issn = {2837-6056},
 journal = {Imaging Neuroscience},
 month = {06},
 pages = {1-15},
 title = {{Do try this at home: Age prediction from sleep and meditation with large-scale low-cost mobile EEG}},
 url = {https://doi.org/10.1162/imag\_a\_00189},
 volume = {2},
 year = {2024}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Diffusion posterior sampling for simulation-based inference in tall data settings</b><br/>
    Linhart J., Victorino Cardoso G., <strong><em>Gramfort A.</em></strong>, Le Corff S., Rodrigues P. (2024)
    <br/>
        <a href="https://arxiv.org/abs/2404.07593">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_6">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_6_content">
            <pre>@misc{linhart2024diffusionposteriorsamplingsimulationbased,
 archiveprefix = {arXiv},
 author = {Linhart, Julia and Victorino Cardoso, Gabriel and Gramfort, Alexandre and Le Corff, Sylvain and Rodrigues, Pedro L. C.},
 eprint = {2404.07593},
 primaryclass = {stat.ML},
 title = {Diffusion posterior sampling for simulation-based inference in tall data settings},
 url = {https://arxiv.org/abs/2404.07593},
 year = {2024}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Physics-informed and Unsupervised Riemannian Domain Adaptation for Machine Learning on Heterogeneous EEG Datasets</b><br/>
    Mellot A., Collas A., Chevallier S., Engemann D., <strong><em>Gramfort A.</em></strong> (2024)
    <br/>
        <a href="https://arxiv.org/abs/2403.15415">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_8">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_8_content">
            <pre>@misc{mellot2024physicsinformedunsupervisedriemanniandomain,
 archiveprefix = {arXiv},
 author = {Mellot, Apolline and Collas, Antoine and Chevallier, Sylvain and Engemann, Denis and Gramfort, Alexandre},
 eprint = {2403.15415},
 primaryclass = {eess.SP},
 title = {Physics-informed and Unsupervised Riemannian Domain Adaptation for Machine Learning on Heterogeneous EEG Datasets},
 url = {https://arxiv.org/abs/2403.15415},
 year = {2024}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Methods and considerations for estimating parameters in biophysically detailed neural models with simulation based inference</b><br/>
    Tolley N., Rodrigues P., <strong><em>Gramfort A.</em></strong>, Jones S. (2024)
        <br/>
        PLOS Computational Biology
            20: (1-29).
    <br/>
        <a href="https://doi.org/10.1371/journal.pcbi.1011108">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_9">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_9_content">
            <pre>@article{10.1371/journal.pcbi.1011108,
 abstract = {Biophysically detailed neural models are a powerful technique to study neural dynamics in health and disease with a growing number of established and openly available models. A major challenge in the use of such models is that parameter inference is an inherently difficult and unsolved problem. Identifying unique parameter distributions that can account for observed neural dynamics, and differences across experimental conditions, is essential to their meaningful use. Recently, simulation based inference (SBI) has been proposed as an approach to perform Bayesian inference to estimate parameters in detailed neural models. SBI overcomes the challenge of not having access to a likelihood function, which has severely limited inference methods in such models, by leveraging advances in deep learning to perform density estimation. While the substantial methodological advancements offered by SBI are promising, their use in large scale biophysically detailed models is challenging and methods for doing so have not been established, particularly when inferring parameters that can account for time series waveforms. We provide guidelines and considerations on how SBI can be applied to estimate time series waveforms in biophysically detailed neural models starting with a simplified example and extending to specific applications to common MEG/EEG waveforms using the the large scale neural modeling framework of the Human Neocortical Neurosolver. Specifically, we describe how to estimate and compare results from example oscillatory and event related potential simulations. We also describe how diagnostics can be used to assess the quality and uniqueness of the posterior estimates. The methods described provide a principled foundation to guide future applications of SBI in a wide variety of applications that use detailed models to study neural dynamics.},
 author = {Tolley, Nicholas and Rodrigues, Pedro L. C. and Gramfort, Alexandre and Jones, Stephanie R.},
 doi = {10.1371/journal.pcbi.1011108},
 journal = {PLOS Computational Biology},
 month = {02},
 number = {2},
 pages = {1-29},
 publisher = {Public Library of Science},
 title = {Methods and considerations for estimating parameters in biophysically detailed neural models with simulation based inference},
 url = {https://doi.org/10.1371/journal.pcbi.1011108},
 volume = {20},
 year = {2024}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Convolution Monge Mapping Normalization for learning on sleep data</b><br/>
    Gnassounou T., Flamary R., <strong><em>Gramfort A.</em></strong> (2023)
        <br/>
        Advances in Neural Information Processing Systems
    <br/>
        <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/21718991f6acf19a42376b5c7a8668c5-Paper-Conference.pdf">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_10">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_10_content">
            <pre>@inproceedings{NEURIPS2023_21718991,
 author = {Gnassounou, Th\'{e}o and Flamary, R\'{e}mi and Gramfort, Alexandre},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {10457--10476},
 publisher = {Curran Associates, Inc.},
 title = {Convolution Monge Mapping Normalization for learning on sleep data},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/21718991f6acf19a42376b5c7a8668c5-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}</pre>
        </div>
</p><p class="post-meta">
    <b>L-C2ST: Local Diagnostics for Posterior Approximations in Simulation-Based Inference</b><br/>
    Linhart J., <strong><em>Gramfort A.</em></strong>, Rodrigues P. (2023)
        <br/>
        Advances in Neural Information Processing Systems
    <br/>
        <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/b0313c2f4501a81d0e0d4a1e8fbf4995-Paper-Conference.pdf">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_11">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_11_content">
            <pre>@inproceedings{NEURIPS2023_b0313c2f,
 author = {Linhart, Julia and Gramfort, Alexandre and Rodrigues, Pedro},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {56384--56410},
 publisher = {Curran Associates, Inc.},
 title = {L-C2ST: Local Diagnostics for Posterior Approximations in Simulation-Based Inference},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/b0313c2f4501a81d0e0d4a1e8fbf4995-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Weakly supervised covariance matrices alignment through Stiefel matrices estimation for MEG applications</b><br/>
    Collas A., Flamary R., <strong><em>Gramfort A.</em></strong> (2024)
    <br/>
        <a href="https://arxiv.org/abs/2402.03345">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_12">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_12_content">
            <pre>@misc{collas2024weaklysupervisedcovariancematrices,
 archiveprefix = {arXiv},
 author = {Collas, Antoine and Flamary, Rémi and Gramfort, Alexandre},
 eprint = {2402.03345},
 primaryclass = {eess.SP},
 title = {Weakly supervised covariance matrices alignment through Stiefel matrices estimation for MEG applications},
 url = {https://arxiv.org/abs/2402.03345},
 year = {2024}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Harmonizing and aligning M/EEG datasets with covariance-based techniques to enhance predictive regression modeling</b><br/>
    Mellot A., Collas A., Rodrigues P., Engemann D., <strong><em>Gramfort A.</em></strong> (2023)
        <br/>
        Imaging Neuroscience
            1: (1-23).
    <br/>
        <a href="https://doi.org/10.1162/imag\_a\_00040">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_14">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_14_content">
            <pre>@article{10.1162/imag_a_00040,
 abstract = {{Neuroscience studies face challenges in gathering large datasets, which limits the use of machine learning (ML) approaches. One possible solution is to incorporate additional data from large public datasets; however, data collected in different contexts often exhibit systematic differences called dataset shifts. Various factors, for example, site, device type, experimental protocol, or social characteristics, can lead to substantial divergence of brain signals that can hinder the success of ML across datasets. In this work, we focus on dataset shifts in recordings of brain activity using MEG and EEG. State-of-the-art predictive approaches on magneto- and electroencephalography (M/EEG) signals classically represent the data by covariance matrices. Model-based dataset alignment methods can leverage the geometry of covariance matrices, leading to three steps: re-centering, re-scaling, and rotation correction. This work explains theoretically how differences in brain activity, anatomy, or device configuration lead to certain shifts in data covariances. Using controlled simulations, the different alignment methods are evaluated. Their practical relevance is evaluated for brain age prediction on one MEG dataset (Cam-CAN, n = 646) and two EEG datasets (TUAB, n = 1385; LEMON, n = 213). Among the same dataset (Cam-CAN), when training and test recordings were from the same subjects but performing different tasks, paired rotation correction was essential (δR2=+0.13 (rest-passive) or +0.17 (rest-smt)). When in addition to different tasks we included unseen subjects, re-centering led to improved performance (δR2=+0.096 for rest-passive, δR2=+0.045 for rest-smt). For generalization to an independent dataset sampled from a different population and recorded with a different device, re-centering was necessary to achieve brain age prediction performance close to within dataset prediction performance. This study demonstrates that the generalization of M/EEG-based regression models across datasets can be substantially enhanced by applying domain adaptation procedures that can statistically harmonize diverse datasets.}},
 author = {Mellot, Apolline and Collas, Antoine and Rodrigues, Pedro L. C. and Engemann, Denis and Gramfort, Alexandre},
 doi = {10.1162/imag_a_00040},
 eprint = {https://direct.mit.edu/imag/article-pdf/doi/10.1162/imag\_a\_00040/2197837/imag\_a\_00040.pdf},
 issn = {2837-6056},
 journal = {Imaging Neuroscience},
 month = {12},
 pages = {1-23},
 title = {{Harmonizing and aligning M/EEG datasets with covariance-based techniques to enhance predictive regression modeling}},
 url = {https://doi.org/10.1162/imag\_a\_00040},
 volume = {1},
 year = {2023}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Repurposing electroencephalogram monitoring of general anaesthesia for building biomarkers of brain ageing: an exploratory study</b><br/>
    Sabbagh D., Cartailler J., Touchard C., Joachim J., Mebazaa A., Vallée F., Gayat É., <strong><em>Gramfort A.</em></strong>, Engemann D. (2023)
        <br/>
        BJA Open
            7: (100145).
    <br/>
        <a href="https://www.sciencedirect.com/science/article/pii/S2772609623000242">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_15">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_15_content">
            <pre>@article{SABBAGH2023100145,
 author = {Sabbagh, David and Cartailler, Jérôme and Touchard, Cyril and Joachim, Jona and Mebazaa, Alexandre and Vallée, Fabrice and Gayat, Étienne and Gramfort, Alexandre and Engemann, Denis A.},
 doi = {https://doi.org/10.1016/j.bjao.2023.100145},
 issn = {2772-6096},
 journal = {BJA Open},
 keywords = {brain age, burst suppression, electroencephalogram (EEG), general anaesthesia, machine learning, propofol, sevoflurane},
 pages = {100145},
 title = {Repurposing electroencephalogram monitoring of general anaesthesia for building biomarkers of brain ageing: an exploratory study},
 url = {https://www.sciencedirect.com/science/article/pii/S2772609623000242},
 volume = {7},
 year = {2023}
}</pre>
        </div>
</p><p class="post-meta">
    <b>FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels</b><br/>
    Staerman G., Allain C., <strong><em>Gramfort A.</em></strong>, Moreau T. (2023)
        <br/>
        Proceedings of the 40th International Conference on Machine Learning
    <br/>
        <a href="https://proceedings.mlr.press/v202/staerman23a/staerman23a.pdf">
            <img src="images/Haltools_pdf.png">
        </a>
        <a href="https://proceedings.mlr.press/v202/staerman23a.html">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_16">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_16_content">
            <pre>@inproceedings{pmlr-v202-staerman23a,
 abstract = {Temporal point processes (TPP) are a natural tool for modeling event-based data. Among all TPP models, Hawkes processes have proven to be the most widely used, mainly due to their adequate modeling for various applications, particularly when considering exponential or non-parametric kernels. Although non-parametric kernels are an option, such models require large datasets. While exponential kernels are more data efficient and relevant for specific applications where events immediately trigger more events, they are ill-suited for applications where latencies need to be estimated, such as in neuroscience. This work aims to offer an efficient solution to TPP inference using general parametric kernels with finite support. The developed solution consists of a fast $\ell_2$ gradient-based solver leveraging a discretized version of the events. After theoretically supporting the use of discretization, the statistical and computational efficiency of the novel approach is demonstrated through various numerical experiments. Finally, the method’s effectiveness is evaluated by modeling the occurrence of stimuli-induced patterns from brain signals recorded with magnetoencephalography (MEG). Given the use of general parametric kernels, results show that the proposed approach leads to an improved estimation of pattern latency than the state-of-the-art.},
 author = {Staerman, Guillaume and Allain, C\'{e}dric and Gramfort, Alexandre and Moreau, Thomas},
 booktitle = {Proceedings of the 40th International Conference on Machine Learning},
 editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
 month = {23--29 Jul},
 pages = {32575--32597},
 pdf = {https://proceedings.mlr.press/v202/staerman23a/staerman23a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {{F}a{DI}n: Fast Discretized Inference for {H}awkes Processes with General Parametric Kernels},
 url = {https://proceedings.mlr.press/v202/staerman23a.html},
 volume = {202},
 year = {2023}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Using convolutional dictionary learning to detect task-related neuromagnetic transients and ageing trends in a large open-access dataset</b><br/>
    Power L., Allain C., Moreau T., <strong><em>Gramfort A.</em></strong>, Bardouille T. (2023)
        <br/>
        NeuroImage
            267: (119809).
    <br/>
        <a href="https://www.sciencedirect.com/science/article/pii/S1053811922009302">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_19">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_19_content">
            <pre>@article{POWER2023119809,
 abstract = {Human neuromagnetic activity is characterised by a complex combination of transient bursts with varying spatial and temporal characteristics. The characteristics of these transient bursts change during task performance and normal ageing in ways that can inform about underlying cortical sources. Many methods have been proposed to detect transient bursts, with the most successful ones being those that employ multi-channel, data-driven approaches to minimize bias in the detection procedure. There has been little research, however, into the application of these data-driven methods to large datasets for group-level analyses. In the current work, we apply a data-driven convolutional dictionary learning (CDL) approach to detect neuromagnetic transient bursts in a large group of healthy participants from the Cam-CAN dataset. CDL was used to extract repeating spatiotemporal motifs in 538 participants between the ages of 18–88 during a sensorimotor task. Motifs were then clustered across participants based on similarity, and relevant task-related clusters were analysed for age-related trends in their spatiotemporal characteristics. Seven task-related motifs resembling known transient burst types were identified through this analysis, including beta, mu, and alpha type bursts. All burst types showed positive trends in their activation levels with age that could be explained by increasing burst rate with age. This work validated the data-driven CDL approach for transient burst detection on a large dataset and identified robust information about the complex characteristics of human brain signals and how they change with age.},
 author = {Power, Lindsey and Allain, Cédric and Moreau, Thomas and Gramfort, Alexandre and Bardouille, Timothy},
 doi = {https://doi.org/10.1016/j.neuroimage.2022.119809},
 issn = {1053-8119},
 journal = {NeuroImage},
 keywords = {Transient bursts, Convolutional dictionary learning, MEG, Ageing, Clustering, Burst rate},
 pages = {119809},
 title = {Using convolutional dictionary learning to detect task-related neuromagnetic transients and ageing trends in a large open-access dataset},
 url = {https://www.sciencedirect.com/science/article/pii/S1053811922009302},
 volume = {267},
 year = {2023}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Optimizing the Noise in Self-Supervised Learning: from Importance Sampling to Noise-Contrastive Estimation</b><br/>
    Chehab O., <strong><em>Gramfort A.</em></strong>, Hyvarinen A. (2023)
    <br/>
        <a href="https://arxiv.org/abs/2301.09696">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_20">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_20_content">
            <pre>@misc{chehab2023optimizingnoiseselfsupervisedlearning,
 archiveprefix = {arXiv},
 author = {Chehab, Omar and Gramfort, Alexandre and Hyvarinen, Aapo},
 eprint = {2301.09696},
 primaryclass = {stat.ML},
 title = {Optimizing the Noise in Self-Supervised Learning: from Importance Sampling to Noise-Contrastive Estimation},
 url = {https://arxiv.org/abs/2301.09696},
 year = {2023}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Deep invariant networks with differentiable augmentation layers</b><br/>
    Rommel C., Moreau T., <strong><em>Gramfort A.</em></strong> (2022)
        <br/>
        Advances in Neural Information Processing Systems
    <br/>
        <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/e7d019329e662fe4685be505befca3bb-Paper-Conference.pdf">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_22">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_22_content">
            <pre>@inproceedings{NEURIPS2022_e7d01932,
 author = {Rommel, C\'{e}dric and Moreau, Thomas and Gramfort, Alexandre},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {35672--35683},
 publisher = {Curran Associates, Inc.},
 title = {Deep invariant networks with differentiable augmentation layers},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/e7d019329e662fe4685be505befca3bb-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Data augmentation for learning predictive models on EEG: a systematic comparison</b><br/>
    Rommel C., Paillard J., Moreau T., <strong><em>Gramfort A.</em></strong> (2022)
        <br/>
        Journal of Neural Engineering
            19: (066020).
    <br/>
        <a href="https://dx.doi.org/10.1088/1741-2552/aca220">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_23">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_23_content">
            <pre>@article{Rommel_2022,
 abstract = {Objective. The use of deep learning for electroencephalography (EEG) classification tasks has been rapidly growing in the last years, yet its application has been limited by the relatively small size of EEG datasets. Data augmentation, which consists in artificially increasing the size of the dataset during training, can be employed to alleviate this problem. While a few augmentation transformations for EEG data have been proposed in the literature, their positive impact on performance is often evaluated on a single dataset and compared to one or two competing augmentation methods. This work proposes to better validate the existing data augmentation approaches through a unified and exhaustive analysis. Approach. We compare quantitatively 13 different augmentations with two different predictive tasks, datasets and models, using three different types of experiments. Main results. We demonstrate that employing the adequate data augmentations can bring up to 45% accuracy improvements in low data regimes compared to the same model trained without any augmentation. Our experiments also show that there is no single best augmentation strategy, as the good augmentations differ on each task. Significance. Our results highlight the best data augmentations to consider for sleep stage classification and motor imagery brain–computer interfaces. More broadly, it demonstrates that EEG classification tasks benefit from adequate data augmentation.},
 author = {Rommel, C\'{e}dric and Paillard, Joseph and Moreau, Thomas and Gramfort, Alexandre},
 doi = {10.1088/1741-2552/aca220},
 journal = {Journal of Neural Engineering},
 month = {nov},
 number = {6},
 pages = {066020},
 publisher = {IOP Publishing},
 title = {Data augmentation for learning predictive models on EEG: a systematic comparison},
 url = {https://dx.doi.org/10.1088/1741-2552/aca220},
 volume = {19},
 year = {2022}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Benchopt: Reproducible, efficient and collaborative optimization benchmarks</b><br/>
    Moreau T., Massias M., <strong><em>Gramfort A.</em></strong>, Ablin P., Charlier P., Dagréou M., la Tour T., Durif G., Dantas C., Klopfenstein Q., Larsson J., Lai E., Lefort T., Malézieux B., Moufad B., Nguyen B., Rakotomamonjy A., Ramzi Z., Salmon J., Vaiter S. (2022)
    <br/>
        <a href="https://arxiv.org/abs/2206.13424">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_24">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_24_content">
            <pre>@misc{benchopt,
 author = {Moreau, Thomas and Massias, Mathurin and Gramfort, Alexandre and Ablin, Pierre and Charlier, Pierre-Antoine Bannier Benjamin and Dagréou, Mathieu and la Tour, Tom Dupré and Durif, Ghislain and Dantas, Cassio F. and Klopfenstein, Quentin and Larsson, Johan and Lai, En and Lefort, Tanguy and Malézieux, Benoit and Moufad, Badr and Nguyen, Binh T. and Rakotomamonjy, Alain and Ramzi, Zaccharie and Salmon, Joseph and Vaiter, Samuel},
 copyright = {Creative Commons Attribution 4.0 International},
 doi = {10.48550/ARXIV.2206.13424},
 keywords = {Machine Learning (cs.LG), Optimization and Control (math.OC), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
 publisher = {arXiv},
 title = {Benchopt: Reproducible, efficient and collaborative optimization benchmarks},
 url = {https://arxiv.org/abs/2206.13424},
 year = {2022}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Repurposing EEG monitoring of general anaesthesia for building biomarkers of brain ageing: An exploratory study</b><br/>
    Sabbagh D., Cartailler J., Touchard C., Joachim J., Mebazaa A., Vallée F., Gayat {., <strong><em>Gramfort A.</em></strong>, Engemann D. (2022)
        <br/>
        medRxiv
            .
    <br/>
        <a href="https://www.medrxiv.org/content/early/2022/05/07/2022.05.05.22274610">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_25">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_25_content">
            <pre>@article{Sabbagh2022.05.05.22274610,
 abstract = {Background EEG is a common tool for monitoring anaesthetic depth but is rarely reused at large for biomedical research. This study sets out to explore repurposing of EEG during anaesthesia to learn biomarkers of brain ageing.Methods We focused on brain age estimation as an example. Using machine learning, we reanalysed 4-electrodes EEG of 323 patients under propofol and sevoflurane. We included spatio-spectral features from stable anaesthesia for EEG-based age prediction applying recently published reference methods. Anaesthesia was considered stable when 95\% of the total power was below a frequency between 8Hz and 13Hz.Results We considered moderate-risk patients (ASA \&lt;= 2) with propofol anaesthesia to explore predictive EEG signatures. Average alpha-band power (8-13Hz) was informative about age. Yet, state-of-the-art prediction performance was achieved by analysing the entire power spectrum from all electrodes (MAE = 8.2y, R2 = 0.65). Clinical exploration revealed that brain age was systematically linked with intra-operative burst suppression {\textendash} commonly associated with age-related postoperative cognitive issues. Surprisingly, the brain age was negatively correlated with burst suppression in high-risk patients (ASA = 3), pointing at unknown confounding effects. Secondary analyses revealed that brain-age EEG signatures were specific to propofol anaesthesia, reflected by limited prediction performance under sevoflurane and poor cross-drug generalisation.Conclusions EEG from general anaesthesia may enable state-of-the-art brain age prediction. Yet, differences between anaesthetic drugs can impact the effectiveness of repurposing EEG from anaesthesia. To unleash the dormant potential of repurposing EEG-monitoring for clinical and health research, collecting larger datasets with precisely documented drug dosage will be key enabling factors.Competing Interest StatementD.E. is a full-time employee of F. Hoffmann-La Roche Ltd.Clinical TrialNCT03876379Funding StatementThis work was supported by a 2018 "medecine numerique" (for digital medicine) thesis grant issued by Inserm (French national institute of health and medical research) and Inria (French national research institute for the digital sciences). It was also partly supported by the European Research Council Starting Grant SLAB ERC-StG-676943.Author DeclarationsI confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.YesThe details of the IRB/oversight body that provided approval or exemption for the research described are given below:The Ethics Advisory Committee (Chairperson Dr Jean Reignier, 48, avenue Claude Vellefaux, Paris, France) gave approval to this work on the 5 January 2016, under the reference CE SRLF 11-356. The SRLF is the French national academic society for anaesthesia and critical care consulted by the department of anaesthesiology at the Lariboisiere hospital (Paris, France).I confirm that all necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived, and that any patient/participant/sample identifiers included were not known to anyone (e.g., hospital staff, patients or participants themselves) outside the research group so cannot be used to identify individuals.YesI understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).YesI have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.YesAll data produced in the present study are available upon reasonable request to the authors.},
 author = {Sabbagh, David and Cartailler, J{\'e}r{\^o}me and Touchard, Cyril and Joachim, Jona and Mebazaa, Alexandre and Vall{\'e}e, Fabrice and Gayat, {\'E}tienne and Gramfort, Alexandre and Engemann, Denis A.},
 doi = {10.1101/2022.05.05.22274610},
 elocation-id = {2022.05.05.22274610},
 eprint = {https://www.medrxiv.org/content/early/2022/05/07/2022.05.05.22274610.full.pdf},
 journal = {medRxiv},
 publisher = {Cold Spring Harbor Laboratory Press},
 title = {Repurposing EEG monitoring of general anaesthesia for building biomarkers of brain ageing: An exploratory study},
 url = {https://www.medrxiv.org/content/early/2022/05/07/2022.05.05.22274610},
 year = {2022}
}</pre>
        </div>
</p><p class="post-meta">
    <b>The Optimal Noise in Noise-Contrastive Learning Is Not What You Think</b><br/>
    Chehab O., <strong><em>Gramfort A.</em></strong>, Hyvarinen A. (2022)
        <br/>
        The 38th Conference on Uncertainty in Artificial Intelligence
    <br/>
        <a href="https://openreview.net/forum?id=SEef8wIj5lc">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_27">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_27_content">
            <pre>@inproceedings{chehab-etal:22,
 author = {Chehab, Omar and Gramfort, Alexandre and Hyvarinen, Aapo},
 booktitle = {The 38th Conference on Uncertainty in Artificial Intelligence},
 copyright = {arXiv.org perpetual, non-exclusive license},
 title = {The Optimal Noise in Noise-Contrastive Learning Is Not What You Think},
 url = {https://openreview.net/forum?id=SEef8wIj5lc},
 year = {2022}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Robust learning from corrupted EEG with dynamic spatial filtering</b><br/>
    Banville H., Wood S., Aimone C., Engemann D., <strong><em>Gramfort A.</em></strong> (2022)
        <br/>
        NeuroImage
            251: (118994).
    <br/>
        <a href="https://www.sciencedirect.com/science/article/pii/S1053811922001239">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_28">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_28_content">
            <pre>@article{banville-etal:2022,
 abstract = {Building machine learning models using EEG recorded outside of the laboratory setting requires methods robust to noisy data and randomly missing channels. This need is particularly great when working with sparse EEG montages (1–6 channels), often encountered in consumer-grade or mobile EEG devices. Neither classical machine learning models nor deep neural networks trained end-to-end on EEG are typically designed or tested for robustness to corruption, and especially to randomly missing channels. While some studies have proposed strategies for using data with missing channels, these approaches are not practical when sparse montages are used and computing power is limited (e.g., wearables, cell phones). To tackle this problem, we propose dynamic spatial filtering (DSF), a multi-head attention module that can be plugged in before the first layer of a neural network to handle missing EEG channels by learning to focus on good channels and to ignore bad ones. We tested DSF on public EEG data encompassing ∼4000 recordings with simulated channel corruption and on a private dataset of ∼100 at-home recordings of mobile EEG with natural corruption. Our proposed approach achieves the same performance as baseline models when no noise is applied, but outperforms baselines by as much as 29.4% accuracy when significant channel corruption is present. Moreover, DSF outputs are interpretable, making it possible to monitor the effective channel importance in real-time. This approach has the potential to enable the analysis of EEG in challenging settings where channel corruption hampers the reading of brain signals.},
 author = {Banville, Hubert and Wood, Sean U.N. and Aimone, Chris and Engemann, Denis-Alexander and Gramfort, Alexandre},
 doi = {https://doi.org/10.1016/j.neuroimage.2022.118994},
 issn = {1053-8119},
 journal = {NeuroImage},
 keywords = {Electroencephalography, Mobile EEG, Deep learning, Machine learning, Noise robustness},
 pages = {118994},
 title = {Robust learning from corrupted {EEG} with dynamic spatial filtering},
 url = {https://www.sciencedirect.com/science/article/pii/S1053811922001239},
 volume = {251},
 year = {2022}
}</pre>
        </div>
</p><p class="post-meta">
    <b>A reusable benchmark of brain-age prediction from M/EEG resting-state signals</b><br/>
    Engemann D., Mellot A., Höchenberger R., Banville H., Sabbagh D., Gemein L., Ball T., <strong><em>Gramfort A.</em></strong> (2022)
        <br/>
        NeuroImage
            262: (119521).
    <br/>
        <a href="https://www.sciencedirect.com/science/article/pii/S105381192200636X">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_30">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_30_content">
            <pre>@article{engemann-etal:2021,
 author = {Engemann, Denis A. and Mellot, Apolline and Höchenberger, Richard and Banville, Hubert and Sabbagh, David and Gemein, Lukas and Ball, Tonio and Gramfort, Alexandre},
 doi = {https://doi.org/10.1016/j.neuroimage.2022.119521},
 issn = {1053-8119},
 journal = {NeuroImage},
 keywords = {Clinical neuroscience, Brain age, Electroencephalography, Magnetoencephalography, Machine learning, Population modeling, Riemannian geometry, Random forests, Deep learning},
 pages = {119521},
 title = {A reusable benchmark of brain-age prediction from M/EEG resting-state signals},
 url = {https://www.sciencedirect.com/science/article/pii/S105381192200636X},
 volume = {262},
 year = {2022}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Shared Independent Component Analysis for Multi-Subject Neuroimaging</b><br/>
    Richard H., Ablin P., Thirion B., <strong><em>Gramfort A.</em></strong>, Hyvärinen A. (2021)
        <br/>
        Advances in Neural Information Processing Systems 34 (NeurIPS)
    <br/>
        <a href="https://arxiv.org/pdf/2110.13502.pdf">
            <img src="images/Haltools_pdf.png">
        </a>
        <a href="https://arxiv.org/abs/2110.13502">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_31">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_31_content">
            <pre>@inproceedings{richard-etal:21,
 author = {Richard, Hugo and Ablin, Pierre and Thirion, Bertrand and Gramfort, Alexandre and Hyv{\"a}rinen, Aapo},
 booktitle = {Advances in Neural Information Processing Systems 34 (NeurIPS)},
 month = {December},
 pdf = {https://arxiv.org/pdf/2110.13502.pdf},
 title = {{Shared Independent Component Analysis for Multi-Subject Neuroimaging}},
 url = {https://arxiv.org/abs/2110.13502},
 year = {2021}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Uncovering the structure of clinical EEG signals with self-supervised learning</b><br/>
    Banville H., Chehab O., Hyvärinen A., Engemann D., <strong><em>Gramfort A.</em></strong> (2021)
        <br/>
        Journal of Neural Engineering
            18: (046020).
    <br/>
        <a href="https://doi.org/10.1088/1741-2552/abca18">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_35">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_35_content">
            <pre>@article{Banville_2021,
 author = {Banville, Hubert and Chehab, Omar and Hyv{\"a}rinen, Aapo and Engemann, Denis-Alexander and Gramfort, Alexandre},
 doi = {10.1088/1741-2552/abca18},
 journal = {Journal of Neural Engineering},
 month = {mar},
 number = {4},
 pages = {046020},
 publisher = {{IOP} Publishing},
 title = {Uncovering the structure of clinical {EEG} signals with self-supervised learning},
 url = {https://doi.org/10.1088/1741-2552/abca18},
 volume = {18},
 year = {2021}
}</pre>
        </div>
</p><p class="post-meta">
    <b>Deep Recurrent Encoder: A scalable end-to-end network to model brain signals</b><br/>
    Chehab O., Defossez A., Loiseau J., <strong><em>Gramfort A.</em></strong>, King J. (2021)
    <br/>
        <a href="https://arxiv.org/abs/2103.02339">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_36">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_36_content">
            <pre>@misc{chehab2021deep,
 archiveprefix = {arXiv},
 author = {Chehab, Omar and Defossez, Alexandre and Loiseau, Jean-Christophe and Gramfort, Alexandre and King, Jean-Remi},
 eprint = {2103.02339},
 primaryclass = {q-bio.NC},
 title = {Deep Recurrent Encoder: A scalable end-to-end network to model brain signals},
 url = {https://arxiv.org/abs/2103.02339},
 year = {2021}
}</pre>
        </div>
</p><p class="post-meta">
    <b>CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG Signals</b><br/>
    Rommel C., Moreau T., Paillard J., <strong><em>Gramfort A.</em></strong> (2022)
        <br/>
        International Conference on Learning Representations
    <br/>
        <a href="https://openreview.net/forum?id=6IYp-35L-xJ">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_41">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_41_content">
            <pre>@inproceedings{rommel2022cadda,
 author = {Rommel, C{\'e}dric and Moreau, Thomas and Paillard, Joseph and Gramfort, Alexandre},
 booktitle = {International Conference on Learning Representations},
 title = {{CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG Signals}},
 url = {https://openreview.net/forum?id=6IYp-35L-xJ},
 year = {2022}
}</pre>
        </div>
</p><p class="post-meta">
    <b>HNPE: Leveraging Global Parameters for Neural Posterior Estimation</b><br/>
    Rodrigues P., Moreau T., Louppe G., <strong><em>Gramfort A.</em></strong> (2021)
        <br/>
        Advances in Neural Information Processing Systems 34 (NeurIPS)
    <br/>
        <a href="https://arxiv.org/pdf/2102.06477.pdf">
            <img src="images/Haltools_pdf.png">
        </a>
        <a href="https://arxiv.org/abs/2102.06477">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_42">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_42_content">
            <pre>@inproceedings{Rodrigues2021,
 author = {Rodrigues, Pedro L. C. and Moreau, Thomas and Louppe, Gilles and Gramfort, Alexandre},
 booktitle = {Advances in Neural Information Processing Systems 34 (NeurIPS)},
 month = {December},
 pdf = {https://arxiv.org/pdf/2102.06477.pdf},
 title = {{HNPE}: Leveraging Global Parameters for Neural Posterior Estimation},
 url = {https://arxiv.org/abs/2102.06477},
 year = {2021}
}</pre>
        </div>
</p><footer class="footer">
    <p>
        &copy; Alexandre Gramfort &ndash;
        <!-- Built with joy. -->
        Built with <a href="https://github.com/PurePelicanTheme/pure-single">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
         - <a href="http://fontawesome.io/" title="Font Awesome">Font Awesome</a>
         - <a href="https://jpswalsh.github.io/academicons/" title="academicons">Academicons</a>
    </p>
</footer>            </div>
            </div>
        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });

        // Handle toggle of bibtex entries
        $( ".publi-bibtex-button" ).each(function( index ) {
            $(this).unbind('click').on('click', function () {
                $('#' + $(this).attr('id') + '_content').toggle('slide');
            });
        });
    </script>

    </script>
</body>
</html>